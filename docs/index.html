<!DOCTYPE html>
<html>
<head>
  <meta charset="utf-8">
  <meta name="viewport" content="width=device-width, initial-scale=1">
  <script type="module" src="https://ajax.googleapis.com/ajax/libs/model-viewer/3.1.1/model-viewer.min.js"></script>
  <title>TV-3DG: Mastering Text-to-3D Customized Generation with Visual Prompt</title>


  <link href="https://fonts.googleapis.com/css?family=Google+Sans|Noto+Sans|Castoro"
        rel="stylesheet">

  <link rel="stylesheet" href="./static/css/bulma.min.css">
  <link rel="stylesheet" href="./static/css/bulma-carousel.min.css">
  <link rel="stylesheet" href="./static/css/bulma-slider.min.css">
  <link rel="stylesheet" href="./static/css/fontawesome.all.min.css">
  <link rel="stylesheet"
        href="https://cdn.jsdelivr.net/gh/jpswalsh/academicons@1/css/academicons.min.css">
  <link rel="stylesheet" href="./static/css/index.css">
  <link rel="icon" href="./static/images/favicon.svg">

  <script src="https://ajax.googleapis.com/ajax/libs/jquery/3.5.1/jquery.min.js"></script>
  <script defer src="./static/js/fontawesome.all.min.js"></script>
  <script src="./static/js/bulma-carousel.min.js"></script>
  <script src="./static/js/bulma-slider.min.js"></script>
  <script src="./static/js/index.js"></script>
</head>
<body>

<nav class="navbar" role="navigation" aria-label="main navigation">
  <div class="navbar-brand">
    <a role="button" class="navbar-burger" aria-label="menu" aria-expanded="false">
      <span aria-hidden="true"></span>
      <span aria-hidden="true"></span>
      <span aria-hidden="true"></span>
    </a>
  </div>
  <div class="navbar-menu">
    <div class="navbar-start" style="flex-grow: 1; justify-content: center;">
      <a class="navbar-item" href="https://keunhong.com">
      <span class="icon">
          <i class="fas fa-home"></i>
      </span>
      </a>

      <div class="navbar-item has-dropdown is-hoverable">
        <a class="navbar-link">
          More Research
        </a>
        <div class="navbar-dropdown">
          <a class="navbar-item" href="https://vp3d-cvpr24.github.io">
            VP3D
          </a>
          <a class="navbar-item" href="https://github.com/EnVision-Research/LucidDreamer">
            LucidDreamer
          </a>
          <a class="navbar-item" href="https://me.kiui.moe/lgm">
            LGM
          </a>
          <a class="navbar-item" href="https://ip-adapter.github.io">
            IP-Adapter
          </a>
          <a class="navbar-item" href="https://github.com/yjhboy/Hyper3DG">
            Hyper3DG
          </a>
        </div>
      </div>
    </div>

  </div>
</nav>


<section class="hero">
  <div class="hero-body">
    <div class="container is-max-desktop">
      <div class="columns is-centered">
        <div class="column has-text-centered">
          <h1 class="title is-1 publication-title">TV-3DG: Mastering Text-to-3D Customized Generation with Visual Prompt</h1>
          <div class="is-size-5 publication-authors">
            <span class="author-block">
              <a href="">Jiahui Yang</a><sup>1,2</sup>,
            </span>

            <span class="author-block">
              <a href="">Jianxun Cui*</a><sup>1</sup>
            </span>

            <span class="author-block">
              <a href="https://scholar.google.com/citations?hl=zh-CN&user=BszRJxkAAAAJ">Yongjia Ma</a><sup>2</sup>,
            </span>
            
              <span class="author-block">
              <a href="https://scholar.google.com/citations?user=3-9aEOQAAAAJ&hl=zh-CN&oi=ao">Wenzhang Sun</a><sup>2</sup>,
            </span>

            <span class="author-block">
              <a href="https://scholar.google.com/citations?user=L8tcNioAAAAJ&hl=zh-CN&oi=ao">Donglin Di</a><sup>1,2</sup>,
            </span>

            <span class="author-block">
              <a href="https://github.com/fkcptlst">Chaofan Luo</a><sup>2,3</sup>,
            </span>

            <span class="author-block">
              <a href="">Wei Chen</a><sup>2</sup>,
            </span>

            <span class="author-block">
              <a href="https://scholar.google.com/citations?hl=zh-CN&user=ro8lzsUAAAAJ">Xun Yang*</a><sup>3</sup>
            </span>
            
          </div>

          <div class="is-size-5 publication-authors">
            <span class="author-block"><sup>1</sup>Harbin Institute of Technology.</span>
            <span class="author-block"><sup>2</sup>Space AI, Li Auto Inc.</span>
            <span class="author-block"><sup>3</sup>University of Science and Technology of China.</span>
          </div>

          <div class="column has-text-centered">
            <div class="publication-links">
              <!-- PDF Link. -->
              <span class="link-block">
                <a href=""
                   class="external-link button is-normal is-rounded is-dark">
                  <span class="icon">
                      <i class="fas fa-file-pdf"></i>
                  </span>
                  <span>Paper</span>
                </a>
              </span>
              <span class="link-block">
                <a href=""
                   class="external-link button is-normal is-rounded is-dark">
                  <span class="icon">
                      <i class="ai ai-arxiv"></i>
                  </span>
                  <span>arXiv</span>
                </a>
              </span>
              <!-- Video Link. -->
              <!-- <span class="link-block">
                <a href=""
                   class="external-link button is-normal is-rounded is-dark">
                  <span class="icon">
                      <i class="fab fa-youtube"></i>
                  </span>
                  <span>Video</span>
                </a>
              </span> -->
              <!-- Code Link. -->
              <span class="link-block">
                <a href="https://github.com/yjhboy/TV-3DG"
                   class="external-link button is-normal is-rounded is-dark">
                  <span class="icon">
                      <i class="fab fa-github"></i>
                  </span>
                  <span>Code</span>
                  </a>
              </span>
              
            </div>

          </div>
        </div>
      </div>
    </div>
  </div>
</section>

<section class="hero teaser">
  <div class="container is-max-desktop">
    <div class="hero-body">
      <!-- <video id="teaser" autoplay muted loop playsinline height="100%">
        <source src="./static/videos/video_teaser.mp4"
                type="video/mp4">
      </video> -->
      <video id="teaser" autoplay controls loop playsinline height="100%">
        <source src="./static/videos/video_teaser.mp4" type="video/mp4" />
      </video>
      <h2 class="subtitle has-text-centered">
        <b>TV-3DG</b> is a novel customized generation framework that 
        leverages text descriptions and single image guidance to produce 
        high-quality and intricately stylized 3D assets.
      </h2>
    </div>
  </div>
</section>


<section class="section">
  <div class="container is-max-desktop">
    <!-- Abstract. -->
    <div class="columns is-centered has-text-centered">
      <div class="column is-four-fifths">
        <h2 class="title is-3">Abstract</h2>
        <div class="content has-text-justified">
          <p>
            Recent advancements in the text-to-3D field have been substantial. 
            However, the inherent ambiguity of text
            prompts continues to pose a significant challenge in producing
            customized 3D assets. While subsequent works have explored
            using images as conditions to enhance 3D controllability, they
            still struggle to generating high-quality and customized 3D assets.
            To address this challenge, we introduce <b>TV-3DG</b>, a novel customized 
            generation framework that leverages text descriptions and single image 
            guidance to produce high-quality and intricately stylized 3D assets. 
            Our foundational insight stems from pioneering advancements in diffuse models, 
            incorporating a 3D prior model for coarse model initialization, 
            a Visual Prompt Interval Score Matching (VPISM) module for aligning the 
            style and content of the generated 3D asset with the given image and text prompt, 
            and a Semantic-Geometry Calibration (SGC) module for matching the semantic and geometric 
            distribution of 3D rendered images to the text prompt distributions. 
          </p>
        </div>
        <img src="./static/images/TV3DG.png">
        <div class="content has-text-justified">
        <p>
          Figure 1. <b>TV-3DG</b> can achieve customized 3D contents from text prompt and reference image, specifically on text-to-3D task and 3D stylized task.
        </p>
        </div>
      </div>
    </div>
  </div>
</section>

<hr>

<section class="section">
  <div class="container is-max-desktop">
    <!-- Abstract. -->
    <div class="columns is-centered has-text-centered">
      <div class="column is-four-fifths">
        <h2 class="title is-3">Visualization</h2>
        <div class="content has-text-justified">
          <p>
            <b>Visual results of TV-3DG</b> with various customized text and reference visual prompts.
            We extend our gratitude to the Civitai community for providing some of the intricate reference images.
        </p>        
        </div>
        <img src="./static/images/teaser.png">
        <div class="content has-text-justified">
        </div>
      </div>
    </div>
  </div>
</section>

<hr>

<section class="section">
  <div class="container is-max-desktop">
    <!-- Abstract. -->
    <div class="columns is-centered has-text-centered">
      <div class="column is-four-fifths">
        <h2 class="title is-3"> Qualitative Comparisons of 3D Stylized Generation Task</h2>
        <div class="content has-text-justified">
          <p>
            Comparative analysis of 3D stylized generation task between our method and established baselines. 
            Experimental outcomes indicate that our approach proficiently produces stylized 3D assets. For the 
            <a href="https://vp3d-cvpr24.github.io">VP3D</a> baseline, since it is not open-sourced, we compare our results based on their official demo. 
            This corresponds to the example in the top-left corner: "A rabbit, high detailed 3D model". Please zoom in to view details.
        </p>        
        </div>
        <img src="./static/images/VS_ST.png">
        <div class="content has-text-justified">
        </div>
      </div>
    </div>
  </div>
</section>

<hr>

<section class="section">
  <div class="container is-max-desktop">
    <!-- Abstract. -->
    <div class="columns is-centered has-text-centered">
      <div class="column is-four-fifths">
        <h2 class="title is-3"> Qualitative Comparisons of Text-to-3D Generation Task</h2>
        <div class="content has-text-justified">
          <p>
            Comparison of text-to-3D task in our method against existing text-to-3D baselines. 
            Experimental results demonstrate that our method effectively generates complex 3D 
            content closely aligned with the provided text prompts, characterized by high fidelity 
            and detailed intricacy. Limited by the non-open-source nature of the <a
            href="https://vp3d-cvpr24.github.io">VP3D</a> baseline, 
            the comparison shown on the left is restricted to the scenarios presented within VP3D. 
            Please zoom in to view details.
        </p>        
        </div>
        <img src="./static/images/VS_CE.png">
        <div class="content has-text-justified">
        </div>
      </div>
    </div>
  </div>
</section>


<hr>

<footer class="footer">
  <div class="container">
    <div class="columns is-centered">
      <div class="column is-8">
        <div class="content">
          <p>This website is built using the source code from <a
            href="https://github.com/nerfies/nerfies.github.io">Nerfies</a>, and we sincerely appreciate their template.</p>
        </div>
      </div>
    </div>
  </div>
</footer>




</body>
</html>
